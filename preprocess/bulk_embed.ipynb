{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "load_dotenv('~/.secrets')\n",
    "\n",
    "# use open ai to create embeddings\n",
    "openai.api_key = os.getenv('OPENAI_KEY')\n",
    "\n",
    "%reload_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the transcripts + video urls in one big data object..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcripts(file_name: str):\n",
    "    # load text file transcript.txt \n",
    "    df = pd.read_csv('../data/transcribed/' + file_name, on_bad_lines='skip')\n",
    "    return df\n",
    "\n",
    "def compare_string(title1, title2):\n",
    "    words1 = title1.split(' ')\n",
    "    words2 = title2.split(' ')\n",
    "    # check if first 3 words are the same\n",
    "    if words1[:3] == words2[:3]:\n",
    "        return True\n",
    "    \n",
    "def get_video_url(file_name: str):\n",
    "    for video in video_data:\n",
    "        if compare_string(video['title'], file_name.split('.')[0]):\n",
    "            return video['url']\n",
    "\n",
    "transcribed_dir = os.listdir('../data/transcribed')\n",
    "video_data = json.load(open('../data/videos.json', 'r'))\n",
    "\n",
    "transcript_data = []\n",
    "for file in transcribed_dir:\n",
    "    df = load_transcripts(file)\n",
    "    video_url = get_video_url(file)\n",
    "\n",
    "    transcript_data.append({\n",
    "        'video_url': video_url,\n",
    "        'file': file,\n",
    "        'transcript': df,\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now that all the data is in one place, we can embed multiple transcripts in a batched way..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding video:  Are You Smarter Than Meï¼Ÿ - WAN Show April 21, 2023.wav.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a2aa016ed24367bb0e345239309e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding video:  You Deserve Better - WAN Show May 26, 2023.wav.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859e250f162e4bca85d45d3db92a689d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_embeddings(line: str):\n",
    "    return openai.Embedding.create(input=[line], model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# create the embedding for store the emebdding and line\n",
    "embedding_type = np.dtype([\n",
    "    ('embedding', np.float64, (1536,)), \n",
    "    ('line', str, 10000),\n",
    "    ('start_time', np.float64),\n",
    "    ('video_url', str, 1000),\n",
    "])\n",
    "\n",
    "# initialize the embeddings array\n",
    "embeddings = []\n",
    "\n",
    "# how many (s) to embed in 1 go\n",
    "DURATION = 10\n",
    "\n",
    "# iterate through each transcript\n",
    "for transcript in transcript_data:\n",
    "    print(\"Embedding video: \" ,transcript['file'])\n",
    "    video_url = transcript['video_url']\n",
    "    df = transcript['transcript']\n",
    "\n",
    "    embed_text = ''\n",
    "    text_duration = 0\n",
    "    start_time = 0\n",
    "    # iterate through each line in the transcript\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        line = row['text']\n",
    "        # convert time to seconds\n",
    "        start, end = row['start'] / 1000, row['end'] / 1000\n",
    "\n",
    "        # if the time diff is less than embed duration, add to embed text\n",
    "        if text_duration < DURATION:\n",
    "            embed_text += line + ' '\n",
    "            text_duration += end - start\n",
    "            continue\n",
    "        \n",
    "        arr = (\n",
    "            get_embeddings(embed_text),\n",
    "            embed_text,\n",
    "            start_time,\n",
    "            video_url\n",
    "        )\n",
    "        embeddings.append(arr)\n",
    "        # restart from this line\n",
    "        embed_text = line\n",
    "        start_time = end\n",
    "        text_duration = 0\n",
    "\n",
    "embeddings = np.array(embeddings, dtype=embedding_type)\n",
    "# remove embeddings with sum 0\n",
    "embeddings = embeddings[~np.all(embeddings['embedding'] == 0, axis=1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings generated, now time to insert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('embeddings.npy', allow_pickle=True)\n",
    "\n",
    "from sqlalchemy import Integer, String, create_engine, text, JSON, insert, Float\n",
    "from sqlalchemy.orm import declarative_base, mapped_column, Session\n",
    "from pgvector.sqlalchemy import Vector\n",
    "\n",
    "postgres_pwd = os.environ.get('POSTGRES_PWD')\n",
    "# supabase engine\n",
    "db_uri = 'postgresql://postgres:{}@db.wiagwfwjtbojsbzmeduv.supabase.co:5432/postgres'.format(postgres_pwd)\n",
    "engine = create_engine(db_uri)\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Document(Base):\n",
    "    \"\"\"\n",
    "    A class used to represent a Document\n",
    "    \"\"\"\n",
    "\n",
    "    __tablename__ = 'docs'\n",
    "\n",
    "    id = mapped_column(Integer, primary_key=True, autoincrement=True)\n",
    "    embedding = mapped_column(Vector(1536))\n",
    "    line = mapped_column(String)\n",
    "    meta = mapped_column(JSON)\n",
    "    video_url = mapped_column(String)\n",
    "    timestamp = mapped_column(Float)\n",
    "    created_at = mapped_column(String, server_default=text('NOW()'))\n",
    "    \n",
    "\n",
    "# TODO: what does this line do?\n",
    "Base.metadata.drop_all(engine)\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "documents = [\n",
    "    dict(\n",
    "        embedding=embedding['embedding'], \n",
    "        line=embedding['line'],\n",
    "        meta={\n",
    "            'line': embedding['line'], \n",
    "            'start_time': embedding['start_time']\n",
    "        },\n",
    "        video_url=embedding['video_url'],\n",
    "        timestamp=embedding['start_time']\n",
    "    ) for embedding in embeddings\n",
    "]\n",
    "\n",
    "session = Session(engine)\n",
    "session.execute(insert(Document), documents)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving embeddings locally\n",
    "np.save('embeddings.npy', embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also append data about youtube to DB..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Integer, String, create_engine, text, JSON, insert, Float\n",
    "from sqlalchemy.orm import declarative_base, mapped_column, Session\n",
    "from pgvector.sqlalchemy import Vector\n",
    "\n",
    "postgres_pwd = os.environ.get('POSTGRES_PWD')\n",
    "# supabase engine\n",
    "db_uri = 'postgresql://postgres:{}@db.wiagwfwjtbojsbzmeduv.supabase.co:5432/postgres'.format(postgres_pwd)\n",
    "engine = create_engine(db_uri)\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Videos(Base):\n",
    "    \"\"\"\n",
    "    A class used to represent a Document\n",
    "    \"\"\"\n",
    "\n",
    "    __tablename__ = 'videos'\n",
    "\n",
    "    id = mapped_column(Integer, primary_key=True, autoincrement=True)\n",
    "    title = mapped_column(String)\n",
    "    url = mapped_column(String)\n",
    "    created_at = mapped_column(String, server_default=text('NOW()'))\n",
    "    \n",
    "\n",
    "# TODO: what does this line do?\n",
    "Base.metadata.drop_all(engine)\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "videos = [\n",
    "    dict(\n",
    "        title=video['file'].split('.')[0],\n",
    "        url=video['video_url']\n",
    "    ) for video in transcript_data\n",
    "]\n",
    "\n",
    "session = Session(engine)\n",
    "session.execute(insert(Videos), videos)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
